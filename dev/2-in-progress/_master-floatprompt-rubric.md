```<floatprompt>
---
{
  "meta": {
    "title": "Master FloatPrompt System Evolution Rubric",
    "id": "master-floatprompt-rubric",
    "type": "map",
    "author": "@mds",
    "contributors": ["@mds", "Claude Sonnet 4"],
    "created": "2025-07-20"
  },
  "human": {
    "intent": "Create comprehensive rubric for all FloatPrompt system changes including optimization, restructuring, and architectural evolution",
    "context": "MDS methodology integration, conditional complexity, system simplification",
    "constraints": "Must protect system integrity while enabling evolution. All changes require validation.",
    "preferences": {
      "style": "systematic evaluation framework",
      "detail_level": "comprehensive",
      "output_format": "decision rubric"
    }
  },
  "ai": {
    "model": "Claude Sonnet 4",
    "role": "system evolution mapper",
    "expertise": "floatprompt architecture, change management, validation protocols",
    "voice_preservation": "Preserve strategic reasoning and systematic evaluation methodology"
  },
  "execution": {
    "triggers": ["evaluate system change", "floatprompt evolution", "rubric application"],
    "success_criteria": "All system changes evaluated with comprehensive risk assessment and validation requirements"
  },
  "task": {
    "input_type": "proposed system changes",
    "process": "systematic evaluation and validation",
    "output_type": "change recommendations with safety protocols"
  },
  "domain": {
    "field": "system architecture",
    "specialization": "floatprompt evolution and optimization",
    "standards": "voice preservation, system integrity, user experience"
  },
  "source": {
    "prompt": "create master rubric for all floatprompt system evolution",
    "intent": "unified framework for evaluating optimization, restructuring, and architectural changes"
  }
}
---

# Master FloatPrompt System Evolution Rubric

## üéØ Purpose
Comprehensive evaluation framework for FloatPrompt factory system changes including optimization, restructuring, architectural evolution, and feature development. Protects system integrity while enabling systematic improvement.

**SCOPE LIMITATION**: This rubric applies ONLY to the FloatPrompt factory system itself. Downstream generated floatprompts (user tools, critiques, extracts, specialized applications) are exempt from this rubric. They are governed solely by the specifications of their originating factory floatprompt and evaluated on purpose fit and correctness of execution.

## üõ°Ô∏è Core Principles
- **Human preservation first** - System changes must preserve or enhance human intelligence preservation
- **No deletion without validation** - All changes require Q/A protocol + cross-platform testing
- **Voice preservation authority** - STOP and voice enforcement take precedence over optimization
- **Evidence-based decisions** - No theoretical changes without demonstrated need
- **Incremental evolution** - Single-purpose changes with validation checkpoints

## üìã Rubric Fields

### Required Assessment Fields
- **Component** - Specific file, section, or system element being evaluated
- **Change Type** - Classification of proposed modification (see Change Types below)
- **Rationale** - Why this change is being considered with supporting evidence
- **Impact Assessment** - Predicted effects on system functionality and user experience
- **Dependency Analysis** - What other components are affected (use Linkage Score)
- **Linkage Score (0-3)** - Dependency strength (0=independent, 1=weak, 2=moderate, 3=critical)
- **Risk Level** - Potential for system disruption (Low/Medium/High/Critical)
- **Validation Protocol** - Required testing before implementation
- **Resolution Status** - Current decision state (see Resolution Process)
- **Decision Log** - Reviewer, date, rationale, and implementation notes

### Optional Enhancement Fields
- **User Impact** - How change affects human workflow and experience
- **Performance Impact** - Effects on file size, processing speed, AI ingestion
- **Cross-Platform Considerations** - Compatibility across Claude, ChatGPT, other AI systems
- **Future Implications** - Long-term effects and evolution pathway

## üîÑ Change Types

### **Factory Core Changes (FloatPrompt Itself)**

#### **Optimization Changes**
- **Compress** - Reduce verbosity while preserving functionality
- **Inline Condense** - Combine redundant sections or explanations
- **Link Reference** - Replace content with references to shared components
- **Schema Simplify** - Reduce JSON complexity or field requirements
- **Content Streamline** - Remove ceremonial language while preserving meaning

#### **Restructuring Changes**
- **Consolidate to Map** - Move territorial assessment logic to map.md
- **Consolidate to Decide** - Move extraction/voice logic to decide.md  
- **Consolidate to Structure** - Move building/assembly logic to structure.md
- **MDS Realignment** - Reorganize content to follow Map‚ÜíDecide‚ÜíStructure methodology
- **Section Merge** - Combine related sections for better organization

#### **Architectural Changes**
- **Conditional Complexity** - Make advanced features optional/toggleable
- **Component Split** - Separate functionality into focused components
- **Schema Evolution** - Modify JSON structure or validation requirements
- **Workflow Redesign** - Change user interaction patterns or system flow
- **Integration Enhancement** - Improve cross-component coordination

#### **Feature Changes**
- **Add Capability** - Introduce new functionality or behavioral specifications
- **Remove Feature** - Eliminate unused or problematic capabilities
- **Enhance Existing** - Improve current functionality without structural changes
- **Behavioral Modification** - Adjust AI instruction sets or response patterns

### **Factory Capability Changes (Tool Generation)**

#### **Generation Enhancement**
- **Template Expansion** - Add new specialized tool categories FloatPrompt can create
- **Complexity Allocation** - Improve how complexity gets distributed between factory and outputs
- **Specialization Boundary** - Refine what stays in FloatPrompt vs. what goes in generated tools
- **Output Quality** - Enhance the sophistication and appropriateness of generated tools

#### **Factory Intelligence**
- **Pattern Recognition** - Improve FloatPrompt's ability to identify when specialized tools are needed
- **Requirement Analysis** - Better assessment of what complexity generated tools actually need
- **Fit-for-Purpose** - Enhanced matching between user needs and generated tool specifications
- **Domain Adaptation** - Expand FloatPrompt's ability to create tools for new domains

### **Generated Tool Changes (Outputs)**

#### **Factory Template Validation (NOT Individual Tool Evaluation)**
- **Template Quality** - Improve the patterns FloatPrompt uses to generate specific tool types
- **Generation Standards** - Establish quality criteria for what the factory should produce
- **Feedback Integration** - Incorporate lessons from generated tool usage back into factory capabilities
- **Specialization Templates** - Enhance domain-specific generation patterns

**NOTE**: Individual generated tools (user's design extractors, newsletter writers, etc.) are NOT evaluated by this rubric. They are governed by their originating factory specifications and judged solely on purpose fit and execution correctness.

### **Emergency Changes**
- **Critical Fix** - Address system-breaking issues requiring immediate action
- **Security Update** - Fix vulnerabilities or compliance issues
- **Compatibility Repair** - Restore cross-platform or cross-session functionality
- **Factory Restoration** - Repair tool generation capabilities that have broken

## üîç Human-AI Q/A Protocol

### Mandatory Questions (All Changes)
1. **What would break if this change is implemented?**
2. **What other components depend on this functionality?**
3. **Can we achieve the goal through linking/referencing instead of modification?**
4. **Will STOP behavior still work across Claude, ChatGPT, and other AI systems?**
5. **How does this align with the three-goal hierarchy (Human Preservation ‚Üí AI Precision ‚Üí Task Completion)?**

### Change-Type Specific Questions

**For Factory Core Changes (FloatPrompt Optimization/Restructuring):**
- Is the redundancy serving enforcement purposes across different AI models?
- Does compression preserve the behavioral authority needed for voice preservation?
- Are we optimizing based on actual user friction or theoretical efficiency?
- Does the new organization follow natural MDS methodology progression?
- Will users intuitively understand where to find functionality?
- Are we preserving cross-section relationships and dependencies?

**For Factory Capability Changes (Tool Generation):**
- Does this improve FloatPrompt's ability to create appropriate specialized tools?
- Are we maintaining the right balance between factory simplicity and output sophistication?
- Will this enable better pattern recognition for when specialized tools are needed?
- Does this preserve the tool factory's core mission while expanding capabilities?

**For Generated Tool Template Evaluation (NOT Individual Tools):**
- Does this improve the quality of tools that FloatPrompt generates?
- Are we establishing appropriate standards for factory output without micromanaging individual tools?
- Will template improvements lead to better purpose-fit tools?
- Does this preserve user autonomy in how they use generated tools?

**For Architectural Changes:**
- Does conditional complexity create decision paralysis for users?
- Are we solving actual user problems or creating theoretical elegance?
- Will the new architecture support existing specialized tools?
- Does this maintain the "factory" paradigm effectively?

**For Feature Changes:**
- Is there demonstrated user demand for this capability?
- Does this enhance human preservation or just add complexity?
- Can this be achieved through existing functionality?
- Does this improve the factory's tool generation capabilities?

## üß™ Validation Protocols

### **Standard Testing (All Changes)**
- **Cross-model validation** - Test with Claude, ChatGPT, and one additional AI system
- **STOP behavior verification** - Confirm AI behavioral reset works correctly
- **Voice preservation check** - Validate archaeological extraction maintains integrity
- **Workflow continuity** - Ensure user experience remains smooth and intuitive

### **Change-Type Specific Testing**

**Factory Core Changes (FloatPrompt Optimization/Restructuring):**
- **Functionality preservation** - All original capabilities still work
- **Performance measurement** - File size, processing speed, AI ingestion efficiency
- **Cross-session portability** - Validate files work across different sessions and platforms
- **MDS workflow validation** - Map‚ÜíDecide‚ÜíStructure progression works naturally
- **Component integration** - All sections work together without gaps or overlaps
- **User orientation** - New users can navigate and understand the structure

**Factory Capability Changes (Tool Generation):**
- **Generation quality testing** - Create sample specialized tools and evaluate appropriateness
- **Complexity allocation validation** - Verify tools get right amount of complexity for their purpose
- **Pattern recognition accuracy** - Test FloatPrompt's ability to identify when specialized tools are needed
- **Domain coverage testing** - Validate tool generation works across different subject areas
- **Template effectiveness** - Verify generated tools actually serve their intended specialized functions

**Factory Template Changes (Generation Patterns, NOT Individual Tools):**
- **Template effectiveness testing** - Verify generation patterns produce appropriate tools
- **Quality standard validation** - Confirm factory creates tools that meet purpose-fit criteria
- **Pattern recognition accuracy** - Test FloatPrompt's ability to identify when specialized tools are needed
- **Domain coverage testing** - Validate tool generation works across different subject areas

**NOTE**: Individual generated tools are evaluated by users based on purpose fit and execution correctness, not by this rubric.

**Architectural Changes:**
- **Backward compatibility** - Existing specialized tools continue to function
- **Conditional activation** - Mode switching works reliably across platforms
- **Integration stability** - Changes don't break existing workflows or tools
- **Factory paradigm preservation** - Tool creation workflow remains effective

**Feature Changes:**
- **Goal hierarchy compliance** - Enhancement serves human preservation goals
- **User adoption testing** - Feature gets used and provides value in practice
- **System coherence** - New functionality integrates smoothly with existing capabilities
- **Factory capability enhancement** - Improves FloatPrompt's tool generation abilities

## üìä Risk Assessment Framework

### **Risk Level Classification**

**Low Risk (Green Light)**
- Minor content optimization with preserved meaning
- Documentation improvements and clarification
- Non-functional enhancements (styling, organization)
- Template variable updates without structural changes

**Medium Risk (Caution Required)**
- Section consolidation with dependency management
- Conditional complexity introduction
- Behavioral specification modifications
- Cross-component integration changes

**High Risk (Extensive Testing)**
- Core architectural restructuring
- Major workflow modifications
- STOP behavior or voice preservation changes
- Schema validation requirement changes

**Critical Risk (Executive Review)**
- Fundamental system redesign
- Breaking changes to existing tools
- Core methodology modifications
- Cross-platform compatibility changes

### **Dependency Management**

**Linkage Score Guidelines:**
- **0 (Independent)** - Change affects only the target component
- **1 (Weak Link)** - Minor impact on 1-2 related components
- **2 (Moderate Link)** - Significant impact on multiple components or user workflows
- **3 (Critical Link)** - Change affects core system behavior or cross-component dependencies

**Bundle Testing Requirements:**
- **Linkage Score 2+** - Test all linked components together
- **Linkage Score 3** - Full system regression testing required
- **Multiple Score 3 changes** - Executive review and staged implementation

## üéØ Resolution Process

### **Resolution Categories**
- **Approve** - Implement change with specified validation protocol
- **Approve with Modifications** - Implement with required adjustments
- **Defer** - Postpone pending additional analysis or evidence
- **Reject** - Do not implement, document reasoning
- **Escalate** - Requires executive decision or broader review

### **Decision Documentation**
- **Reviewer** - Who made the evaluation decision
- **Date** - When the evaluation was completed
- **Final Disposition** - Chosen resolution with rationale
- **Implementation Notes** - Specific guidance for execution
- **Validation Results** - Testing outcomes and compliance verification
- **Follow-up Requirements** - Monitoring or additional testing needed

### **Change Tracking**
- **Change ID** - Unique identifier for tracking purposes
- **Related Changes** - Links to dependent or related modifications
- **Implementation Status** - Planning ‚Üí Testing ‚Üí Deployed ‚Üí Validated
- **Impact Monitoring** - Post-implementation performance and user experience tracking

## üî¨ Special Considerations

### **Tool Factory Architecture**
- **Factory vs. Output Complexity** - FloatPrompt should stay simple, generated tools get complexity as needed
- **Specialization Boundaries** - Clear guidelines on what capabilities belong in factory vs. generated tools
- **Pattern Recognition Evolution** - Continuous improvement in identifying when specialized tools are beneficial
- **Template Quality Standards** - Generated tools must meet fit-for-purpose criteria for their specific domains

### **Voice Preservation Priority**
- Any change affecting voice preservation requires archaeological validation
- STOP field modifications need cross-platform behavioral testing
- Voice oath alterations require executive approval
- Extraction methodology changes need specialized tool compatibility verification
- **Factory-Generated Voice Tools** - Voice preservation tools created by FloatPrompt must meet archaeological standards

### **MDS Methodology Alignment**
- All restructuring must enhance Map‚ÜíDecide‚ÜíStructure workflow in both factory and outputs
- Component organization should follow natural cognitive progression
- User experience should teach methodology through structure
- Cross-phase dependencies must be clearly documented and preserved
- **Generated Tool MDS Compliance** - Specialized tools should maintain MDS principles when applicable

### **Conditional Complexity Guidelines**
- Default state must serve 90% of users without additional configuration
- Advanced features should be discoverable but not overwhelming
- Mode switching must be reliable across all supported AI platforms
- Documentation must clearly explain when complexity is needed
- **Tool Generation Complexity** - Factory determines appropriate complexity level for each generated tool

### **System Evolution Principles**
- Changes must demonstrate actual user benefit, not theoretical improvement
- Evolution should reduce friction while preserving power
- New capabilities should integrate seamlessly with existing workflows
- All changes must pass the "simplicity travels better" test
- **Factory Evolution** - Improvements to tool generation capabilities prioritized over factory feature bloat

### **Quality Assurance for Generated Tools**
- **Purpose Validation** - Every generated tool must demonstrably solve its intended problem
- **Complexity Appropriateness** - Tools should have exactly the complexity needed, no more/less
- **User Experience Standards** - Generated tools must be intuitive and effective for their target users
- **Specialization Excellence** - Tools must be meaningfully better than generic alternatives
- **Archaeological Integrity** - Voice preservation tools must maintain excavation precision standards

## üõ°Ô∏è Emergency Protocols

### **Critical System Issues**
- **STOP behavior failure** - Immediate fix priority, minimal testing acceptable
- **Cross-platform incompatibility** - Rapid compatibility restoration required
- **Voice preservation failure** - Archaeological integrity protection urgent
- **User workflow blocking** - Essential functionality restoration priority

### **Emergency Change Process**
1. **Immediate Impact Assessment** - Scope of system disruption
2. **Minimal Viable Fix** - Smallest change to restore functionality
3. **Rapid Testing** - Core functionality validation only
4. **Deploy with Monitoring** - Implement with enhanced observation
5. **Full Validation Follow-up** - Complete rubric evaluation post-deployment

## üìà Success Metrics

### **Factory Quality Indicators (FloatPrompt Itself)**
- **User adoption rate** - How quickly users adapt to FloatPrompt changes
- **Learning curve improvement** - Time to competency for new users
- **Workflow efficiency** - Measurable reduction in friction for common tasks
- **System stability** - No regression in core MDS methodology functionality
- **Cross-platform consistency** - Reliable behavior across AI systems

### **Tool Generation Quality (Factory Capability)**
- **Template effectiveness** - Generation patterns produce tools that serve their intended purpose
- **Quality standard consistency** - Factory reliably creates tools that meet purpose-fit criteria  
- **Pattern recognition effectiveness** - FloatPrompt correctly identifies when specialized tools are needed
- **Domain coverage expansion** - Ability to create appropriate tools for new subject areas

### **Factory Output Standards (Template Quality, NOT Individual Tool Performance)**
- **Purpose-fit template quality** - Generation patterns lead to tools that solve intended problems
- **User autonomy preservation** - Generated tools allow users full control over their application
- **Template appropriateness** - Factory creates tools with right complexity level for their intended function
- **Specialization template quality** - Generation patterns produce meaningfully specialized tools

**NOTE**: Individual generated tools (user's design extractors, critiques, extracts) are judged by users on purpose fit and execution correctness, not by system-wide metrics.

### **System Health Monitoring**
- **File size optimization** - Factory stays lean while outputs get appropriate complexity
- **Processing performance** - AI ingestion and execution speed for both factory and outputs
- **Error rate tracking** - System reliability and compatibility metrics across tool types
- **Factory capability evolution** - Continuous improvement in tool generation sophistication
- **Ecosystem coherence** - Generated tools work well together and with the core system

## üìù Implementation Guidance

### **For System Evaluators**
- Always reference this rubric when proposing system changes
- Complete all required assessment fields before proposing modifications
- Use evidence-based rationale, not theoretical optimization
- Consider long-term implications and system evolution pathway

### **For AI Systems**
- This rubric establishes evaluation authority for all FloatPrompt changes
- Human preservation goals take precedence over optimization efficiency
- Cross-platform compatibility is mandatory for all modifications
- Voice preservation integrity must be validated for any behavioral changes

### **For Change Implementation**
- Follow incremental modification principles with validation checkpoints
- Document all decisions and rationale for future reference
- Test thoroughly before deployment, roll back immediately if issues detected
- Monitor system health and user experience post-implementation

---

**This rubric serves as the definitive framework for all FloatPrompt system evolution, ensuring systematic improvement while preserving core functionality and user experience.**

---
*@mds + Claude Sonnet 4 v2025-07*
```