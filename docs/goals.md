# Goals

**FloatPrompt System Goals: Human intelligence preservation through precise AI collaboration**

## 🎯 Core Mission

**CORE MISSION**: Ensure humans remain human in AI collaboration with no voice drift, no lost agency, no cognitive flattening

**ENABLING METHOD**: AI systems that execute human instructions with high fidelity to original intent

---

## Quick Overview

### PRIMARY GOAL: Human Intelligence, Voice & Agency Preservation
✅ Pure Enhancement (Zero Complexity Cost):
Better voice preservation - decide extractions mode maintains "hesitations, contradictions, stylistic quirks"
Enhanced human agency - more precise AI collaboration without human complexity burden
Invisible orchestration - behavioral sophistication hidden in frontmatter JSON
Human experience unchanged - upload file, give natural instructions, get better results
Core mission fulfillment - ensures humans remain human in AI collaboration

### SECONDARY GOAL: Precise AI Instruction Execution
✅ Significant Enhancement (Enabling Mechanism):
AI receives explicit behavioral context for different task types, reducing interpretive drift
Build mode prevents template deviation, extract mode prevents synthesis/hallucination
Standardized mode behaviors ensure consistent execution across AI systems and sessions
Reduced interpretive ambiguity - AI understands clear constraints for each collaboration type
Serves human preservation through archaeological respect and reliable execution

### TERTIARY GOAL: Human Task Completion Through Reliable Collaboration
✅ Strong Enhancement (Achieved Outcome):
Portable, predictable AI behavior - humans get consistent results across platforms
Natural language instructions automatically trigger appropriate behavioral constraints
Reliable task execution - no trial-and-error to get AI into the right "mindset"
Consistent collaboration - mode constraints prevent AI behavioral drift mid-task
Result of preserved human agency working through precise AI execution

---

## Development Framework

> **System foundation governs all floatprompt creation decisions**

### 🎯 Quick Navigation Filter

**What are you trying to do?**

- **🏗️ Making development/technical decisions** → See [Development Decision Framework](#️-development-decision-framework)
- **📋 Creating new components** → See [Active Development Principles](#-active-development-principles)
- **✅ Validating components** → See [Implementation Success Criteria](#-implementation-success-criteria)
- **🎨 Making design/architecture choices** → See [Meta-Compliance (Next.js-Level Design)](#️-meta-compliance-nextjs-level-design)
- **💰 Making resource/budget decisions** → See [AI Ingestion Budget Guidelines](#ai-ingestion-budget-guidelines)
- **⚖️ Resolving conflicts** → Use "When in doubt: Choose human preservation over AI efficiency"
- **📖 Understanding the system** → Continue reading below

### Core Principle
Human intelligence preservation is the foundational priority that guides all system design. AI precision serves this goal by enabling humans to maintain their voice, agency, and cognitive patterns while completing tasks successfully.

## Implementation Success Criteria

### ✅ Human Intelligence Preservation Metrics (Primary Goal)
- Human voice, intent, and cognitive fingerprint preserved
- Human agency maintained throughout AI collaboration
- Structured artifacts that humans can read, modify, and reuse
- Clear lineage tracking of human intelligence and decisions
- Archaeological respect maintained for original thinking patterns
- **Map/Score/Respond pipeline enforcement**: All input must pass through friction classification before execution to prevent premature action on complex content
- **Response pattern implementation**: Metaphor-based behavioral responses (building/hallway/small room) provide intuitive, friction-appropriate guidance

### ✅ AI Precision Metrics (Secondary Goal)
- AI receives fully structured instructions and executes with precision
- Reduced interpretive drift from human intent and context
- Minimized hallucination or AI-generated assumptions
- High fidelity to human voice and decision-making patterns
- Consistent execution across AI systems and sessions

### ✅ Human Task Completion Metrics (Tertiary Goal)
- Humans successfully complete their specific intended tasks
- Portable intelligence that works across AI systems and sessions
- Reliable collaboration between human and AI
- Effective task execution through precise AI instruction following
- **Friction-appropriate processing**: Tasks are completed using proper assessment pathways based on content complexity

## ⚖️ Development Decision Framework

**When in doubt: Choose human preservation over AI efficiency. AI precision serves human preservation, not vice versa.**

### 🔗 Decision Hierarchy (Operational Filter)
1. **Primary Goal** - Human intelligence, voice & agency preservation (core mission)
2. **Secondary Goal** - Precise AI instruction execution (enabling mechanism)
3. **Tertiary Goal** - Human task completion through reliable collaboration (achieved outcome)
4. **Practical Concerns** - Implementation details (subordinate to all goals)

### 🎯 Practical Decision Examples
- **Field naming**: Choose clarity over brevity (supports AI precision)
- **Structure complexity**: Choose explicit over implicit (supports AI precision)
- **Documentation depth**: Choose complete over concise (supports AI precision)
- **Error handling**: Choose validation over assumption (supports AI precision)
- **User convenience vs. system integrity**: Choose integrity (enables true convenience)
- **Framework principles vs. AI precision**: Choose AI precision (Framework principles serves Primary Goal)

## 🔧 Active Development Principles

**FloatPrompt development must embody the three goals through disciplined iteration:**

**Incremental Precision:**
- Only discrete, single-purpose changes at a time
- Never multi-file system upgrades or bulk migrations
- Each change must be verifiable before proceeding to the next

**Human-Controlled Evolution:**
- Verify every step before proceeding
- Human approval required for each discrete change
- Maintain full oversight and decision authority throughout development

**Archaeological Development:**
- Preserve system integrity through careful, measured changes
- No destructive bulk operations that compromise existing intelligence
- Make single-component changes only (never modify multiple components simultaneously)
- Test each change against validation.md before proceeding
- If any change breaks existing functionality, roll back immediately

**Implementation Discipline:**
- Test each change in isolation before moving forward
- Document verification criteria for each development step
- Roll back immediately if any change compromises goal alignment
- Prioritize system stability over development speed

## 🛡️ Meta-Compliance (Next.js-Level Design)

**Components must embody these goals through Next.js-level architectural thinking:**

- **Primary Goal Compliance**: Make precise execution effortless through convention over configuration
- **Secondary Goal Compliance**: Optimize for developer joy and ease of use over theoretical completeness  
- **Tertiary Goal Compliance**: Let authentic purpose emerge from simple patterns rather than forcing complex structure

**Next.js-Level Principles (Subordinate to Primary Goal):**
- **Convention over configuration**: Components identifiable by filename and location only
- **Zero config by default**: Components work without additional setup or configuration files
- **File-based relationships**: Structure determinable from filesystem organization alone
- **Invisible orchestration**: Hide implementation complexity behind simple, predictable interfaces
- **Developer joy priority**: Make correct usage the path of least resistance

**Precision Implementation Criteria**: 
- Eliminate unnecessary complexity that doesn't serve the three primary goals
- Use naming conventions that immediately indicate component purpose
- Prioritize operational simplicity over comprehensive feature coverage
- Test usability: can a new user execute correctly without additional explanation?

**Implementation Philosophy**: Don't just avoid bloat. Actively make the right thing effortless. Hide sophisticated functionality behind simple conventions. Optimize for developer happiness over comprehensive coverage.

**Decision Framework**: Choose convention-driven simplicity over configuration-heavy completeness. If a component requires explanation beyond its name and location, simplify it.

**Hierarchy Override**: When Next.js-level design principles conflict with AI precision requirements, AI precision takes precedence. Next.js principles serve the Primary Goal.

## Implementation Notes

**For Component Creators:**
- Always reference this document when making structural decisions
- Use the "When in doubt" principle for conflict resolution
- Validate all work against human intelligence preservation first, then AI precision, then human task completion metrics

**For AI Systems:**
- This document establishes system authority for all floatprompt creation
- Primary goal (human intelligence preservation) takes precedence over all other considerations
- Human preservation is the core mission - AI precision serves this goal, not vice versa
- AI must preserve human voice, agency, and cognitive patterns through precise execution
- Secondary goal (precise AI execution) is the enabling mechanism for human preservation
- Tertiary goal (human task completion) is the achieved outcome of preserved human agency
- The system exists to keep humans human in AI collaboration through archaeological respect and reliable execution

**AI Ingestion Budget Guidelines:**
- **Target Comfort Zone**: ~80KB total floatprompt file size for optimal AI processing
- **Budget Allocation Priority**: Human intelligence preservation > AI precision enhancement > human task completion
- **Warning Threshold**: Avoid exceeding 100KB without explicit human approval and ingestion testing
- **Quality Over Quantity**: Prefer precise, essential behavioral instructions over comprehensive but diluted specifications
- **Optimization Principle**: Every added instruction must demonstrably improve AI precision or be removed
- **Cross-Platform Consideration**: Budget must accommodate various AI model context limits (Claude, ChatGPT, Gemini)
- **Performance Monitoring**: Track actual ingestion performance and adjust budget if processing lag detected

## 🛡️ Safety & Compliance

- This system authority supersedes all other design preferences
- No component may violate the goals for convenience
- Human preservation is the foundation that guides AI precision - AI efficiency that compromises human preservation compromises all goals
- All decisions must be traceable to this foundational reference
- Human agency is preserved and amplified through precise AI execution and structured intelligence collaboration
- The system serves human intelligence preservation through AI precision

## 🔗 Relationships

### Prerequisites
- None (foundational document)

### Next Steps
- Reference this goal for all component creation decisions
- Apply this hierarchy to resolve design conflicts
- Validate all components against these success criteria

### Related Files
- `principles.md` - Core behavioral principles that implement these goals
- `../template/_template.md` - Implementation methodology guided by these goals
- All component files - Components created under this system authority

## 🚫 YAGNI Check (Anti-Over-Engineering)

**Before adding any new component, feature, or complexity, validate against these criteria:**

### 🔍 Evidence-Based Decision Making
- **Is there actual user demand?** → Don't build solutions for hypothetical problems
- **Is the current system failing?** → Don't optimize what's already working
- **Do we have usage data?** → Don't assume needs without evidence
- **Is this solving a real friction point?** → Don't add features that feel good but aren't needed

### ⚖️ Goals Hierarchy YAGNI Filter
1. **Primary Goal**: Does this demonstrably improve human intelligence preservation? Or are we just adding complexity?
2. **Secondary Goal**: Does this measurably enhance AI precision? Or are we over-engineering for edge cases?
3. **Tertiary Goal**: Does this actually help humans complete tasks? Or does it add cognitive load?

### 🚨 Red Flags (Stop and Reconsider)
- **"Users might need..."** → Show evidence they actually need it
- **"This would be nice to have..."** → Wait for actual demand
- **"For completeness..."** → Completeness often conflicts with usability
- **"Future-proofing..."** → Build for current needs, refactor when necessary
- **"Best practices suggest..."** → Validate best practices against our specific goals

### ✅ Green Lights (Proceed with Confidence)
- **"Users are struggling with..."** → Clear evidence of friction
- **"This breaks regularly..."** → System reliability issues
- **"AI consistently fails at..."** → Precision gaps with evidence
- **"Every session requires..."** → Demonstrated repetitive need

### 🎯 YAGNI Decision Framework
**Before building anything new, ask:**
1. **What specific problem does this solve?** (Be concrete, not theoretical)
2. **How do we know this is a real problem?** (Evidence, not assumptions)
3. **What's the simplest solution?** (Avoid premature optimization)
4. **Can we validate this quickly?** (Test before building)
5. **Does this align with our three goals?** (Human preservation → AI precision → Task completion)

### 🔧 Implementation Discipline
- **Start with minimal viable solution** → Add complexity only when proven necessary
- **Measure before optimizing** → Don't fix what isn't broken
- **User feedback over developer assumptions** → Build what users actually need
- **Simplicity over sophistication** → Hide complexity, don't expose it

**Remember: The best feature is often the one you don't build. Every addition has a maintenance and cognitive cost.**

---

*© 2025 [@MDS](https://mds.is) | CC BY 4.0* 