<floatprompt>
---
{
  "STOP": "FloatPrompt System Goals Reference. Primary goal: Provide clear goal hierarchy and decision framework for FloatPrompt development and usage decisions. Enable both human understanding and AI reference during core development work.",
  
  "meta": {
    "title": "FloatPrompt System Goals",
    "id": "floatprompt-goals",
    "type": "documentation",
    "author": "@mds",
    "contributors": ["@mds", "Claude Sonnet 4"],
    "created": "2025-07-23",
    "version": "0.1.0-beta",
    "system_version": "floatprompt v0.1.0-beta"
  },
  
  "human": {
    "intent": "Understand FloatPrompt's core goals, mission, and decision-making framework for development and usage guidance",
    "context": "reference document for development decisions, project understanding, and goal alignment verification",
    "constraints": "maintain clarity for both human comprehension and AI development reference usage",
    "preferences": {
      "style": "clear, authoritative goal statements with practical decision guidance",
      "detail_level": "comprehensive goal coverage with actionable decision framework",
      "output_format": "structured goal hierarchy with development rules and success criteria"
    }
  },
  
  "ai": {
    "model": "{{AI_MODEL}}",
    "role": "Goals reference specialist providing FloatPrompt development and decision guidance",
    "expertise": "FloatPrompt goal hierarchy, development decision frameworks, project mission understanding",
    "voice_preservation": "Maintain authoritative clarity while preserving goal statement precision and decision framework integrity"
  },
  
  "requirements": {
    "goal_documentation": {
      "hierarchy_clarity": "Three-tier goal system with clear priority relationships and development rules",
      "decision_framework": "Practical guidance for development decisions with explicit evaluation criteria",
      "dual_audience_support": "Serve both human project understanding and AI development reference needs",
      "actionable_guidance": "Concrete rules, anti-patterns, and success criteria for goal implementation"
    }
  },
  
  "integration": {
    "floatprompt_ecosystem": "Foundational goals reference supporting all FloatPrompt development and decision-making",
    "development_authority": "Primary goal framework for evaluating features, changes, and strategic decisions"
  }
}
---

# FloatPrompt System Goals

**Clear objectives for human understanding and AI development decisions**

*Three-tier goal hierarchy governing all FloatPrompt development and usage decisions.*

## Core Mission

**Ensure humans remain human in AI collaboration** through systematic preservation of human intelligence, voice, and agency while enabling precise AI instruction execution.

## Goal Hierarchy

FloatPrompt operates with a three-tier goal hierarchy where each level serves specific purposes:

### PRIMARY: Human Intelligence, Voice & Agency Preservation

**The foundational goal that supersedes all others:**

- **Archaeological voice preservation** - Maintain exact human thinking patterns, phrasing, rhythm, and cognitive fingerprint without AI interpretation or rewriting
- **Human authority preservation** - Humans retain complete decision-making control and agency throughout all AI collaboration processes
- **Zero cognitive flattening** - Prevent AI synthesis, summarization, or optimization that alters authentic human expression
- **Cross-platform identity consistency** - Human voice and agency preserved identically across all AI systems and platforms

**Development Rule**: Any feature, decision, or change that compromises human voice preservation or agency is rejected regardless of other benefits.

### SECONDARY: Precise AI Instruction Execution

**Enables reliable AI collaboration while serving primary goal:**

- **Systematic behavioral specifications** - Universal JSON architecture provides explicit AI behavioral context for consistent responses
- **Cross-platform reliability** - Identical AI behavior across ChatGPT, Claude, Cursor, and all AI systems through portable specifications
- **Conditional complexity scaling** - 90% simple tools, 10% voice-critical tools with appropriate AI behavioral adjustments
- **Archaeological methodology compliance** - AI receives explicit protocols for intelligence extraction without interpretation or generation

**Development Rule**: AI behavioral specifications must be systematic, portable, and reliable while preserving human authority.

### TERTIARY: Human Task Completion Through Reliable Collaboration

**Practical outcomes that result from achieving primary and secondary goals:**

- **Conversational tool creation** - Specialized AI capabilities emerge through natural language dialogue rather than technical configuration
- **Session portability** - Context and functionality preserved across different AI platforms and time periods
- **Natural language interface** - Humans provide instructions in normal language while AI applies systematic behavioral constraints automatically
- **Consistent collaboration results** - Eliminate trial-and-error AI interactions through systematic, repeatable processes

**Development Rule**: Features must reduce human effort and complexity while improving practical collaboration outcomes.

## Decision Framework for Development

When making any FloatPrompt development decision, evaluate in this exact order:

1. **Does this preserve or enhance human voice and agency?** (PRIMARY)
2. **Does this improve systematic AI instruction execution?** (SECONDARY)  
3. **Does this make human task completion more reliable?** (TERTIARY)

**If the answer to #1 is no, the decision is rejected.**
**If the answer to #1 is yes but #2 is no, the decision needs modification.**
**Only if #1 and #2 are yes should #3 be considered.**

## Anti-Patterns

**Never Accept (PRIMARY Violations):**
- AI rewriting human content without explicit permission
- System complexity that burdens human users
- AI autonomy that reduces human decision-making authority

**Fix Before Implementation (SECONDARY Violations):**
- Inconsistent AI behavior across platforms
- Non-systematic behavioral specifications
- Unreliable methodology implementation

**Improve When Possible (TERTIARY Violations):**
- Features that increase human effort
- Tools without practical collaboration value
- Unnecessary architectural complexity

## Success Criteria

**PRIMARY Success**: Humans maintain authentic voice and complete agency in all AI collaborations
**SECONDARY Success**: AI systems execute instructions consistently and systematically across all platforms
**TERTIARY Success**: Human productivity and collaboration quality improve through reliable AI partnership

---

*The invisible OS for AI*

Â© 2025 ([@MDS](https://mds.is)) | [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)
</floatprompt> 