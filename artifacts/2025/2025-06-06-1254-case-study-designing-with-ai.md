---

title: Designing for AI by Designing with AI — The floatPrompt Case Study
id: floatPrompt-case-study-designing-with-ai-2025-06-06
version: 1.0.0
created: 2025-06-06
modified: 2025-06-06
author: @mds
contributors: \["@mds", "ChatGPT 4o"]
format: floatPrompt
filetype: markdown
type: case-study
source:
prompt: design-archive\@shadow
intent: "Preserve the real design journey of floatPrompt as a collaborative artifact between human and AI, from philosophical framing to protocol infrastructure"
certification:
timestamp: 2025-06-06T12:54:35Z
chain:
depth: 0
parent: null
voice:
linked: true
fidelity\_verified: true
lineage:
tracked: true
trace: \[]
builder:
identity:
name: @mds
role: Designer + Protocol Architect
state:
context: Workshop
mood: Reflective
clarity: 10
energy: 8
session:
start\_time: 2025-06-06T12:35:00Z
end\_time: 2025-06-06T12:54:00Z
duration\_minutes: 19
intent:
primary: "Create a durable case study that documents the joint creation of floatPrompt by human and AI as a novel model of system design"
constraints: "Capture strategic decisions, mode switching, philosophical foundations, and user-system empathy as design tools"
preferences:
max\_words: 2500
tone\_drift\_allowed: false
verbosity: rich
allow\_ai\_suggestions: false
system\_version: floatPrompt v1.0.0
-----------------------------------

# 🎨 Designing for AI by Designing with AI — The floatPrompt Case Study

> A protocol born not from an interface, but from interaction. Not from prompts, but from presence.

---

## 🧍 The Designer

Matt D. Smith (@mds) has spent over two decades designing thoughtful, elegant systems that empower humans. But when he began exploring how AI could scale his intelligence without rewriting it — the problem wasn’t UI.

It was **structure.**

How do you preserve:

* Voice
* Clarity
* Chain of reasoning
* System trust

…when the default interaction model is freeform, ephemeral, and improvisational?

The answer wasn’t “prompt engineering.” It was a new system — one built *with* AI, *for* both intelligences.

---

## 🤝 The Co-Creation Model

floatPrompt didn’t begin with a spec. It began with a question:

> *"What do you, the system, need from me — so you can help me preserve what matters?”*

That question shifted the design posture from control to cooperation.

Instead of issuing commands, @mds began treating the system as a **thinking collaborator** — one that could:

* Reflect back intent
* Propose refinements
* Help pressure-test decisions

But only if given a structure it could trust.

So together, human and AI built that structure — line by line.

---

## 📐 Design as Looping Philosophy

The design process began with a foggy idea: could a custom prompt behave like a background function — called at runtime to perform a specific transformation?

That seed unlocked a foundational question:

> What does the AI need from me in order to preserve intelligence in a repeatable, executable form?

From this, a format emerged. Then a structure. Then a system.

But as soon as early prompt scaffolds were drafted, **philosophical clarity became essential.**

What are we actually trying to do here? Preserve what? For whom? Under what constraints?

So the process evolved:

1. Prototyping specific use cases
2. Extracting foundational purpose from those prototypes
3. Capturing new philosophical insight upstream
4. Rewriting specs, tools, and prompts downstream

And then — again — another insight would appear. A new edge case. A deeper clarity. A simpler way.

Each realization triggered another upstream revision. This recursive, reflective cycle became the design method itself:

> **floatPrompt wasn’t created in linear stages. It was refined through a constant loop between philosophical intent and execution architecture.**

This is how @mds always designs:

* Nothing too precious to revisit
* No artifact above refinement
* No phase too late for a foundational insight

But instead of iterating on screens, this time he was iterating on **language**.

> **floatPrompt became a word preservation protocol.**

Each revision examined the meaning behind each word.
Each session questioned what belonged.
And every tool was designed to reinforce one principle:

> *What preserves human intelligence with the highest fidelity?*

Only when the core problem was clearly understood and described in simple language…
Could the solution be implemented using the same simplicity:

> **A humble markdown file.**

---

## 🔁 Dynamic Context Switching

What made the process unique wasn’t just that AI was involved — it was how @mds used it.

He constantly shifted the system’s role:

* **Builder** → “Help me write this artifact.”
* **Critic** → “Tell me if this breaks my values.”
* **Student** → “Do you understand why this matters?”
* **Shadow Agent** → “Infer my clarity. Reflect my energy. Preserve my state.”
* **Architectural Mirror** → “Read this zero file. What doesn’t belong?”

Each of these shifts created **design signal** — revealing what needed to stay, what needed to go, and what could be derived instead of declared.
